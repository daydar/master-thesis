\documentclass[11pt,a4paper]{report} 

% Für doppelseitigen Ausdruck (nur bei > 60 Seiten sinnvoll)
% \usepackage{ifthen}
% \setboolean{@twoside}{true}
% \setboolean{@openright}{true} 

\include{preamble} % alle Pakete und Einstellungen

% Hier anpassen 
% \newcommand{\welchethesis}{Bachelor}
\newcommand{\welchethesis}{Master}
\newcommand{\thesisofwas}{of Science}
\newcommand{\titel}{Data Mining komplexer Datenstrukturen aus PDF-Dokumenten}
\newcommand{\kurztitel}{Data Mining PDF Dokumente}
\newcommand{\autor}{Deniz Aydar}
\newcommand{\datum}{25. Juli 2022} % Abgabedatum
\newcommand{\ort}{Wiesbaden}
\newcommand{\referent}{Prof.\ Dr.\ Dirk Krechel}
\newcommand{\korreferent}{Prof.\ Dr.\ Philipp Schaible}

\begin{document}
\include{vorspann} % Titelseite, Erklärungen, etc.

\begin{abstract} 
PDF-Dokumente besitzen viele Informationen aus denen sich neue Daten generieren lassen können.
Doch das Extrahieren von solchen Daten ist heutzutage immer noch mit Hürden verbunden.
Dies gilt auch für die Dokumente die in den Prozessen von Autohäusern und deren Kfz-Werkstätten verwendet 
und anschließend gelagert werden.
Um die Frage zu beantworten, inwiefern neue Daten aus diese Art von Dokumenten verarbeiten lassen, 
wird im Rahmen dieser Arbeit ein System konzipiert und entwickelt welches es ermöglichen soll weiteres Wissen zu gestalten.

\end{abstract}

\tableofcontents


\chapter{Einleitung}\label{chap:einf}

„Digitalisierung im Alltag voranbringen“ – Das war einer der Wahlslogans während der Bundestagswahl 2021. 
Gemeint war damit eine zunehmende Digitalisierung im privaten Alltag vieler Bürger:innen, 
aber auch in der Wirtschaft machte sich wachsend der Wunsch nach mehr digitalen Alternativen breit (vgl. Bundesregierung 2021). 
Dieser Wunsch beinhaltete vor allem einen Wechsel von gängigen Papierformen verschiedenster Dokumente hin
zu denselben in digitaler Ausprägung. 

Genau jenes Bedürfnis nach Digitalisierung betrifft auch die vielen Arbeitnehmer:innen und Händler:innen in Autohäusern und deren Kfz-Werkstätten, 
die durch ihre beruflichen Tätigkeiten mit einer Vielzahl an Unterlagen, 
Dokumenten oder Belegen arbeiten müssen. Unter dieser Vielzahl fallen Dokumente wie Werkstatt-, Kauf- und Mietverträge 
sowie Rechnungen oder Diagnoseberichte. 

Jene Beschäftigte in einigen Autohäusern und deren Kfz-Werkstätten sind Kund:innen bei ilexius GmbH. 
Ilexius bietet Enterprise-Resource-Planning (ERP) Systeme an, mit Hilfe derer Arbeitsaufträge und Arbeitsschritte innerhalb des 
täglichen Arbeitsprozesses in Autohäusern und deren Werkstätten durch Digitalisierung 
vereinfacht werden. In Kooperation von ilexius GmbH werde ich daher die Problematik meiner Thesis, die ich im folgenden
noch genauer beschreiben werde, lösen und in die Tat umsetzen.

Durch eine Digitalisierung jener Dokumente eröffnen sich Vorteile wie bessere Zugänglichkeit, 
größere Langlebigkeit und vor allem eine angepasste und leichtere Nutzung, 
die zu einer höheren Effektivität innerhalb täglicher Arbeitsschritte führt.
Durch bisherige erste Schritte der Digitalisierung sind diese benötigten Dokumente 
bereits elektronisch aufgearbeitet und den Beschäftigten in Autohäusern und deren Kfz-Werkstätten zur Verfügung gestellt worden. 

Die Folge dessen ist, dass alle Dokumente standardisiert sind und dadurch die in den Dokumenten beinhalteten Informationen 
neu verarbeitet werden können. Eine Extraktion der Daten der einzelnen Dokumente ist jedoch nur eingeschränkt möglich, 
da die Struktur im gängigen Gebrauch im Dateiformat Portable Document Format (PDF) festgelegt ist. 

Jene Limitierung der Datenextraktion wirkt sich gleichermaßen auf die Dealer-Management-Systeme (DMS), 
mit solchen die Mitarbeiter:innen ihr Prozesse abwickeln, aus. Der daraus resultierende Arbeitsaufwand, 
welcher dabei entsteht, um die Daten wiederverwendbar zu konstruieren, ist derzeit enorm. 

\section{Zielsetzung}\label{sec:ziel}

Aus diesem Grund möchte ich innerhalb dieser Master-Thesis ein System entwickeln, 
das genau jene Problematik erleichtert und löst.
Innerhalb üblicher Methoden werden heutzutage die Daten zunächst über eine grafische Anzeige mithilfe 
einer bereits existierenden Benutzeranwendung via gängiges Kopieren und Einfügen entnommen. 
Dieser Schritt funktioniert zwar im Regelfall, ist jedoch oftmals stark fehleranfällig und kann lückenhaft sein. 

In so einem Fall muss das Einfügen und Kopieren manuell durchgeführt werden, was bei einer riesigen Menge an Dokumente zu einer monotonen Arbeit führt. 
Andernfalls können die Daten eigenhändig abgeschrieben werden – jener Vorgang benötigt jedoch viele Ressourcen.
Eher geeignet ist es, einen Datenkonverter für die PDF Dateien zu nutzen, um so die Dokumente in Bilder beispielsweise umzuwandeln, 
wodurch die Daten zugänglicher sind, aber immer noch verarbeitet werden müssen, was den gesamten Vorgang als eine Notlösung wirken lässt.

Aufgrund dieser bisherigen teils aufwendigen und mit Fehlern verbundenen Möglichkeiten möchte ich mich in meiner Thesis 
von diesen Optionen abwenden und das Data-Mining nutzen. 
Das Data-Mining soll eine Automatisierung unterstützen, mit der Daten aus dem PDF-Dokument extrahiert werden. 
Allein über das Data-Mining ist es möglich, Inhalte zu extrahieren und für andere Systeme bereit zu stellen. 

Der Unterschied zum gängigen Data-Mining liegt dabei in den Einschränkungen des Dateiformats: 
der Quelltext einer solchen Datei stellt erstens keine klare Hierarchie der Daten dar und zweitens 
besitzt es durch das Fehlen von Markierungen keine Informationen darüber, 
was die Daten an sich darstellen sollen~\cite{docsumoPDFScraperScrape2022}. 

Mit Hilfe dieser Technik des Data-Minings soll es ermöglicht werden, aktuelle Prozesse detaillierter zu steuern und zu überwachen. 
Des Weiteren können unter anderem Abgleiche von Rechnungen mit dem System durchgeführt werden 
und weitere Datenanalyse und Reporting kreiert werden.
Mit dem derzeitigen Stand der Datenextraktion können jedoch lediglich Agierende aus dem technischen Bereich arbeiten. 
Die Technologien hierfür benutzen unterschiedliche Ansätze und müssen daher zunächst für diesen Fall ausgewählt werden. 

Damit jedoch auch für Agierende innerhalb des technischen Bereichs die Nutzung nicht zu abstrakt bleibt, 
soll durch die Entwicklung eines Systems der Zugriff greifbarer gestaltet werden, welches wiederum eine benutzerfreundliche Anwendung zur Verfügung stellen soll. 
Darüber hinaus muss eine Automatisierung vorhanden sein, um auch eine große Datenmenge verarbeiten zu können. 
Des Weiteren sollen die Vorgänge eine niedrigere Fehlerquote aufzeigen. 
Die Prozesse müssen außerdem während des gesamten Ablaufs über eine Steuerung und Regelung kontrollierbar sein.
Solche Prozesse können zum Beispiel über Regeln festgelegt beziehungsweise gesteuert werden, 
die bei einer Erfüllung weitere Aktionen oder Regeln auslösen können.

Diese beschriebene Eigenschaft kann durch eine symbolische künstlichen Intelligenz (KI) abgedeckt werden, 
welche eine vorgegebene Verarbeitung möglich macht. 
Hiermit bezeichnet man einen altmodischen Ansatz der KI, bei der über das Festlegen von Symbolen 
menschliches Wissen in einer Logik gehalten wird und diese benutzt wird um weiteres Wissen zu generieren~\cite{dicksonWhatSymbolicArtificial2019}.
Durch eine Parametrisierung einer solchen KI kann dann die Unschärfe der ausgewählten Daten festgelegt werden, 
damit eine Feineinstellung stattfinden kann. 
Das heißt, der Benutzer eines solchen Systems soll sich beginnend von groben Definitionen für die Verarbeitung 
zu einer detaillierten und angepassteren Definition über Feedback des Systems hinarbeiten. 

Mit Hilfe dieser Annäherung an Definitionen und Regeln kann so für eine bessere Erfolgsquote gesorgt werden. 
Zudem kann der Ansatz des Machine Learnings (ML), wobei erfolgreiche Verarbeitungen einem System antrainiert werden, 
weitere Dokumente aus Daten extrahieren. 
Hierbei ist noch offen, welcher Typ des Machine Learnings sich für diesen Fall eignet.

Beide Ansätze – der der symbolischen KI und der des Machine Learnings – bieten als Option die Entwicklung einer grafischen interaktiven Entwicklungsumgebung (IDE) an. 
Jene soll das Festlegen von Definitionen und Regeln erlauben, mit welchen die Dokumente verarbeitet werden können. 
Außerdem soll diese Oberfläche verschiedene Funktionalitäten anbieten und auch Feedback sowohl bei einem problemlosen Lauf 
als auch bei einem fehlerhaften Lauf zurückgeben. 

Des Weiteren soll das System es ermöglichen Änderungen der Definitionen anzumerken und Unterschiede zu erstellen, 
womit auch bisherige Ergebnisse angezeigt werden.
Die Festlegung von Definitionen und Regeln soll außerdem durch eine Ansicht der Dokumente unterstützt werden.
Insgesamt wird das System die zwei Ansätze als Subsysteme aufteilen um die Umsetzung zu modularisieren und einen Vergleich zu ermöglichen.

\section{Ablauf}\label{sec:ablauf}

Um genau dieses optimale System für das beschriebene Szenario entwickeln zu können, werde ich in dieser Arbeit wie folgt vorgehen: 

Für eine vollständige Auseinandersetzung soll eine weitere Analyse stattfinden,
damit die vorhandenen Grundlagen für den Anwendungsfall evaluiert werden können. 
Das heißt, es werden mit Hilfe der Funktionalitäten der Bibliotheken Ergebnisse 
auf Basis der Datensätze erzeugt, um die Erfolgsquoten zu überprüfen. 
Diese werden dann verglichen und ausgewertet. Parallel dazu soll die Umgebung 
für die Entwicklung eingerichtet werden, mit der die Implementierung der Systeme stattfinden soll. 

Danach widme ich mich der Konzeption und der Entwicklung des Systems.
Diese beginnt mit der symbolischen KI als ein Subsystem des gesamtem Projekts, sodass ein direkterer Ansatz ermöglicht wird. 
Die Entwicklung hierbei wird im Wasserfall-Ansatz, einem Ansatz bei der phasenweise die Eigenschaften einer solchen KI umgesetzt werden, 
um eine Grundlage für die nächste Komponente zur Verfügung zu stellen.

Bei dieser Komponente handelt es sich um die interaktive Entwicklungsumgebung, die den Zugang für den Benutzer zum System darstellt.
Deswegen folgt im nächsten Schritt die Konzeptionierung und Entwicklung der interaktiven Entwicklungsumgebung, 
welche sich während der Entwicklung der symbolischen KI parallelisieren lässt. 
Sobald das Gerüst der Benutzeroberfläche fertiggestellt ist, möchte ich dies mit der symbolischen KI verbinden.

Als Gegenstück wird sich dann mit dem Machine Learning Subsystem, bei der gleichermaßen eine Konzeptionierung und Entwicklung stattfindet, gewidmet.
Hier wird das bisherige Gesamtkonstrukt in einem iterativen Ansatz umgesetzt, sodass der Hauptteil so früh wie möglich verfügbar ist, 
damit das Training des ML-Systems durch die Dokumente auch zeitnah starten kann. 
Auf das Auswerten dieses Subsystems folgt eine Anpassung dessen. 

Danach wird das Software Testing für die beiden Subsysteme eingeführt. 
Mit Unit Testing, Integration Testing und Functional Testing wird das erfolgreiche Ausführen gewisser Eigenschaften abgedeckt.
Dies dient wiederum als Grundlage dafür, die Continuous Integration (CI) für das System einzuführen, 
womit eine sichere und konsistente Entwicklung nach dem Prototyping angeboten wird.  

Wenn dann aber die Systeme gegeben sind, kann das grafische Tool weiter angepasst werden, welches 
sich dann mit den Systemen verbinden soll, um die Ausführbarkeit der Funktionalitäten zu überprüfen. 
Um ein gemeinsames System zu ermöglichen, welches dann gegebenenfalls weitere Testschritte bedarf,
werden dann die Komponenten zusammengeführt.  
Sobald jenes eine erfolgreiche Form annimmt, wird der Teil der Continuous Integration mit einbezogen, 
mit jener das System einen Zustand der Instandhaltung annehmen kann. 
Über Testing sollen so mögliche Fehlerquellen entdeckt werden, bevor diese überhaupt auftreten können.

Unter die Zielsetzung für meine beiden eben genannten Ansätze fallen die Kundendaten mit den Eigenschaften wie 
Name, Firma, Adresse und Kundennummer, die Fahrzeugdaten worunter Fahrgestellnummer, Modell, 
Farbe, Motor, Erstzulassung, Letzter/nächster Service und TÜV fallen und 
die Abrechnungsdaten wie die Jobs mit Arbeitspositionen und Teilen, Preise etc. 

Dazu stehen als weitere Grundlage mehr als 10.000 annotierte unterschiedliche Dokumente mit genau den Daten, 
die extrahiert werden sollen, als Datenbank zur Verfügung. 
In Zukunft sollen für das Mengengerüst mehr als 100.000 Dokumente pro Jahr bearbeitet werden. 
Hierbei ist es aber auch möglich, aus den bereits bestehenden Daten einen Pool für den Lernprozess bzw. 
für die Verifikation zu bilden.

Zum Schluss werde ich die Ergebnisse des gesamten Systems betrachten und einen Ausblick zu der Thematik geben.

\chapter{Hintergrund}\label{chap:hint}

Um die Problematik detaillierter darzustellen und um eine Übersicht zu ermöglichen, 
wird in diesem Kapitel der Rahmen der Problematik aus technischer Sicht genauer dargestellt.
Hierbei werden die möglichen Technologien abgewogen und evaluiert. 
Zunächst jedoch wird der Kontext ausführlicher erklärt.

\section{Kontext}\label{sec:kon}

Im Automobilbereich wird der Verkauf von Kraftfahrzeugen in zwei Segmente aufgeteilt: dem Sales-Bereich, bei dem es sich um den Verkauf 
von Neu- und Gebrauchtwagen handelt und dem After-Sales-Bereich, bei jenem eine Bindung zum Kunden über den Verkauf von 
Verschleiß- und Ersatzteilen geschaffen wird.~\cite{theuererWasMachtSales}
Diese Aufteilung der Segmente wird ebenfalls von den Autohäusern angewendet, zugleich werden für diese jeweils gängige Abläufe als Prozesse benutzt.

Für den After-Sales-Bereich bietet ilexius GmbH zwei Arten von ERP-Systeme an. 
Die erste Art ist das von der Automobilmarke Jaguar Land Rover finanzierte `vTab', welches eine Plattform für elektronische Fahrzeugkontrollen 
und ein Backend für Jaguar Land Rover Mitarbeiter:innen, mit dem die Autohäuser bewertet werden können, anbietet.
Die zweite Art mit dem Namen `ATT' ist eine Plattform. Mit derjenigen können Autohäuser ihre Arbeitsprozesse in Schrift, Sprache und Bild dokumentieren.
Die Dokumentation erfolgt mittels mobiler Endgeräte und werden an das ERP-System weitergeleitet, sodass die Dokumentation archiviert werden kann.

Die ERP-Systeme, die bereits im Kapitel~\ref{sec:ziel} beschrieben worden sind, unterstützen damit die Kunden:innen von ilexius GmbH 
in den Autohäusern und deren Werkstätten mit der Planung, der Steuerung sowie der Verwaltung von verschiedenen Aufgaben in ebenjenem After-Sales-Bereich.

Eine Art der Aufgaben sind Arbeitsaufträge, bei der es sich in den meisten Fällen um die Behandlung eines Autos inklusive Kundendaten handelt. 
Diese wiederum unterteilen sich in einzelne Arbeitsschritte, die den gesamten Auftrag in einzelne Teilschritte den Arbeitsauftrag vervollständigen.

Sind diese Aufträge abgeschlossen, benutzen die Autohäuser ihre DMS, um eine Rechnung zu erstellen und diese im ERP-System zu archivieren.
Das ERP bietet des Weiteren eine Schnittstelle für diese Dokumente, wie z.B die Rechnungen oder die Garantieaufträge an, 
die allein über Scanner die Dokumente übertragen. 
Dort werden die Dokumente verarbeitet und mit Hilfe eines OCR Scanners digitalisiert. 

Aktuell ist allerdings die Digitalisierung nicht in der Lage, einen Kontext beziehungsweise (bzw.) eine Semantik für diese Dokumente zu erstellen.
Idealerweise kann dies genutzt werden, um aus den Dokumenten Arbeitsaufträge zu generieren und somit zu digitalisieren.
Demzufolge ergibt sich hier an der Stelle die Möglichkeit, einen neuen Ansatz zu testen, sodass die Informationen 
aus diesen Dokumenten als Daten erhaltbar sind.

\section{Analyse}\label{sec:ana}

Das Extrahieren von Daten ist eine gängige Methode um Informationen aus verschiedenen Systemen wie Datenbanken 
oder Software as a Service (SaaS) Plattformen zu beschaffen~\cite{stichdataWhatDataExtraction}. 
Durch diese Beschaffung können die Daten weiter verarbeitet werden um neue Lösungsmöglichkeiten für das eigene System anzubieten.
Die Arten des Extrahierens unterscheiden sich hierbei im Zeitverlauf und der Herangehensweise. 
So können Diese extrahiert werden sobald Änderungen der Daten beobachtet oder mitgeteilt werden, 
wodurch die Daten nach und nach beschafft werden.

Des Weiteren gibt es die Option eine komplette Extraktion durch zu führen. 
Dieser Ansatz kann sich in vielen Fällen als nachteilig erweisen, da die Daten jedes mal 
bei Anpassungen der ursprünglichen Information neu verarbeitet werden müssen.
Da sich die Problematik im Rahmen der Thesis auf Dokumente, die bereits im ERP-System archiviert  wurden, 
bezieht, trifft dieser Fall hier nicht zu.

\subsection{Extraktionswerkzeuge}\label{sec:exwerk}

Für das Data Mining von PDF Dateien existieren bereits Lösungen, die von großen Unternehmen wie Amazon Web Services (AWS) 
oder Adobe bereits angeboten werden. 
So nutzen Produkte wie Textractor~\cite{amazonIntelligenteExtraktionText} von AWS oder Adobes Extractor API~\cite{developersExtractTextPDF} Künstliche Intelligenz, Machine Learning und Optical Character Recognition (OCR) 
um die Extraktion der Daten zu ermöglichen. 
Unternehmen wie ABBYY~\cite{abbyyPDFSoftwareOpen} habe sich bereits auf diesem Gebiet spezialisiert 
und sind erfolgreich mit der Datenextraktion. 
Auch existieren bereits Open-Source Bibliotheken, die sich mit dem Entnehmen der Daten aus PDF Dokumenten beschäftigen.

Die Meisten davon lassen sich hinsichtlich der Aufteilung der Aufgaben gruppieren. 
So erlauben unter anderem PDFMiner~\cite{unixuserPDFMiner} oder Apache Tika~\cite{apacheApacheTikaApache} Texte aus PDF Dokumenten zu gewinnen. 
Funktionalitäten für das Extrahieren von Daten aus Tabellen bieten Projekte wie 
Tabula~\cite{tabulapdfTabulapdfTabulaTabula} oder Camelot~\cite{camelotCamelotPDFTable2022}
an womit ein weiterer Aspekt durch die Nutzung abgedeckt wäre. 

Bei Beiden zeigen sich niedrige Fehlerquoten auf~\cite{atlanhqComparisonOtherPDF} und die Nutzung von einer Fuzzy Logik. 
Camelot ermöglicht dazu noch ein Web Interface womit die simple Extraktion über einen Browser lokal stattfinden kann.
Andere Bibliotheken wie Textricator~\cite{measuresMeasuresforjusticeTextricatorTextricator} sind umfangreicher gestaltet 
und ergeben geeignete Schnittstellen für die Anfragen spezifischer Inhalte. 
Doch auch wenn dies mit textbasierten Dokumenten funktioniert und der Export flexibel ist, 
können zunächst weder nicht-textbasierte noch komplexere PDF Dokumente verarbeitet werden. 
Des Weiteren sind die Verarbeitungen nicht automatisierbar und die Nutzergruppe 
wird durch eine fehlende grafische Komponente eingeschränkt.

Aus dieser Problematik kommend, zeigt sich, dass community-angetriebene Projekte wie PdfMiner.six~\cite{pdfminerWelcomePdfminerSix}, 
welches eine Abspaltung des bereits erwähnten PdfMiner ist, und PdfPlumber~\cite{singer-vinePdfplumber2022}, 
welches wiederum auf PdfMiner.six basiert, als geeignete Alternativen darstellen. 
PdfPlumber bietet im Vergleich zu seinem Ausgangsprojekt dazu noch eine Tabellenextraktion und bietet für beide Aspekte 
der Extraktion eine Schnittstelle an. 

Die Hürden für eine komplett automatische Extraktion bestehen trotzdem noch.
So ist nämlich nicht klar, wie das zu erwartende Verhalten der Logik der Extraktion für den generellen Fall auszusehen hat.
Eine differenzierte Extraktion für weitere Eigenschaften eines Dokuments wie die Zeilenumbrüche von Absätzen, 
die Seitennummern, die Kopf- und Fußzeilen, die Formatierung et cetera (etc.) ist daher nötig.
Die Frage, die sich dabei stellt ist, welche Eigenschaften eines Dokuments genau zusätzlich extrahiert werden sollen. 
Um eine Auswahl zu treffen, müssen die Arten der Dokumente, die in dem ERP-System auftreten, genauer durchleuchtet werden.

\subsection{Dokumentarten}\label{sec:dokart}

Bei den Dokumenten, die in das ERP-System eingescannt werden, handelt es sich in der Mehrheit um Garantie- und Werkstattaufträge sowie Rechnungen. 
Jedes Autohaus benutzt hierbei ein individuelles Muster für die Arten der Dokumente.
Dem Umfang dieser Thesis geschuldet werde ich mich daher auf drei Dokumententypen von unterschiedlichen Autohäusern beschränken 
und anhand jener drei Typen mein Vorgehen exemplarisch demonstrieren.

In Abbildung~\ref{fig:care_g} wird die erste Art eines Auftrags dargestellt.
Bei diesem digitalen Schriftstück handelt es sich zunächst von der Form her um eine Garantierechnung.
In der oberen Hälfte befindet sich das Adressfeld, welches die Kundeninformationen im genormten Adressformat enthält, 
und ein weiterer Abschnitt, welches die Fahrzeugdaten festhält.

Hierbei ist zu beobachten, dass dieser Abschnitt sich mit einer Tabelle vergleichen lässt, 
da die einzelnen Einträge mit jeweils unterschiedlich großen Abständen verteilt dargestellt werden 
aber gleichzeitig noch eine Gesamthöhe pro Spalte beziehungsweise eine Gesamtbreite pro Höhe einer Tabelle erfüllen.
Jedoch fällt auf, dass sich, im Gegensatz zur Anzahl der Zeileneinträge, die Anzahl der Spalteneinträge pro Zeile unterscheidet.
Außerdem fehlen jegliche Einrahmungen beziehungsweise Trennlinien für die Zeilen und die Spalten.

Dagegen wird im unteren Bereich eine Tabellenform durch die Aufzählung der einzelnen Arbeitsaufträge dargestellt.
Bei dieser Tabelle existiert nur für die Kopfzeile eine untere Trennlinie.


\begin{figure}[htb]
    \centering
    \frame{\includegraphics[width=.7\textwidth]{images/care_garantieauftrag.pdf}}
    \caption{Exemplar eines Garantieauftrags}
~\label{fig:care_g}
\end{figure}

\begin{figure}[htb]
    \centering
    \frame{\includegraphics[width=.7\textwidth]{images/formel1_rechnung.pdf}}
    \caption{Exemplar einer Rechnung}
~\label{fig:formel1_r}
\end{figure}

\begin{figure}[htb]
    \centering
    \frame{\includegraphics[width=.7\textwidth]{images/kfz3000_werkstattauftrag.pdf}}
    \caption{Exemplar eines Werkstattauftrags}
~\label{fig:kfz3000_w}
\end{figure}


\chapter{Konzeption und Umsetzung}\label{chap:konundum} %KAPITEL

Für den Sprung zur Umsetzung bedarf es als Nächstes die Konzeption des technischen Rahmens. 

\chapter{Ergebnisse}\label{chap:erg}




\chapter{Ausblick und Fazit}\label{chap:auf}
 
Im Rahmen der Abschlussarbeit wurde 
 technische Funktionalitäten eingeführt werden um dem Kapitän die Webanwendung als PWA anzubieten.

Insgesamt eignen sich Webanwendungen um Ressourcen übersichtlicher darzustellen und mobil zu beobachten.
Auch können Offline-Zustände dem Benutzer trotzdem erlauben Aspekte der Anwendung weiter zu benutzen.
Aus den Konzepten und der Umsetzung ergeben sich viele weitere Ideen und Ansätze, die realisierbar sind und implementiert werden können.  

\newpage

% Listen wenn überhaupt ans Ende und nicht an den Anfang.
% Meist ist das aber unnötig.
%\listoffigures % Liste der Abbildungen 
%\listoftables % Liste der Tabellen
% \newpage

\bibliography{thesis}
\bibliography{online}
\bibliographystyle{plain} % Literaturverzeichnis
\begin{btSect}{thesis} % mit bibtopic Quellen trennen
\section*{Literaturverzeichnis}
\btPrintCited{}
\end{btSect}
\begin{btSect}{online}
\section*{Online-Quellen}
\btPrintCited{}
\end{btSect}
% dann mit "bibtex thesis1" und "bibtex thesis2" arbeiten

\end{document}
;;; Local Variables:
;;; ispell-local-dictionary: `de_DE-neu'
;;; End:
